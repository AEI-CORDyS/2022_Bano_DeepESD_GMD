{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downscaling Multi-Model Climate Projection Ensembles with Deep Learning (DeepESD): Contribution to CORDEX EUR-44"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Geoscientific Model Development***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**J. Baño-Medina, R. Manzanas, E. Cimadevilla, J. Fernández, J. González-Abad, A.S. Cofiño, and J.M. Gutiérrez**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook reproduces the results presented in **Downscaling Multi-Model Climate Projection Ensembles with Deep Learning (DeepESD): Contribution to CORDEX EUR-44**, submitted to *Geoscientific Model Development* by *J. Baño-Medina, R. Manzanas, E. Cimadevilla, J. Fernández, J. González-Abad, A.S. Cofiño and J.M. Gutiérrez*. \n",
    "This paper presents *DeepESD*, the first dataset of high-resolution (0.5º) climate change projections (up to 2100) of daily precipitation and temperature over Europe obtained with deep learning techniques (in particular convolutional neural networks) from an ensemble of eight global climate models from the Coupled Model Intercomparison Project version 5 (CMIP5)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Preparing-the-R-environment-and-working-directories\" data-toc-modified-id=\"Preparing-the-R-environment-and-working-directories-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Preparing the R environment and working directories</a></span><ul class=\"toc-item\"><li><span><a href=\"#Convolutional-Neural-Networks-(CNNs)\" data-toc-modified-id=\"Convolutional-Neural-Networks-(CNNs)-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Convolutional Neural Networks (CNNs)</a></span></li></ul></li><li><span><a href=\"#DeepESD\" data-toc-modified-id=\"DeepESD-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>DeepESD</a></span><ul class=\"toc-item\"><li><span><a href=\"#Preparing-the-predictor-datasets\" data-toc-modified-id=\"Preparing-the-predictor-datasets-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Preparing the predictor datasets</a></span></li><li><span><a href=\"#Precipitation-downscaling\" data-toc-modified-id=\"Precipitation-downscaling-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Precipitation downscaling</a></span></li><li><span><a href=\"#Temperature-downscaling\" data-toc-modified-id=\"Temperature-downscaling-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Temperature downscaling</a></span></li></ul></li><li><span><a href=\"#Dynamical-climate-models\" data-toc-modified-id=\"Dynamical-climate-models-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Dynamical climate models</a></span><ul class=\"toc-item\"><li><span><a href=\"#Ensemble-of-Global-Climate-Models-(GCMs)\" data-toc-modified-id=\"Ensemble-of-Global-Climate-Models-(GCMs)-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Ensemble of Global Climate Models (GCMs)</a></span></li><li><span><a href=\"#Ensemble-of-Regional-Climate-Models-(RCMs)\" data-toc-modified-id=\"Ensemble-of-Regional-Climate-Models-(RCMs)-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Ensemble of Regional Climate Models (RCMs)</a></span></li></ul></li><li><span><a href=\"#Results\" data-toc-modified-id=\"Results-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Results</a></span><ul class=\"toc-item\"><li><span><a href=\"#Ensemble-mean-and-bias-with-respect-to-E-OBS\" data-toc-modified-id=\"Ensemble-mean-and-bias-with-respect-to-E-OBS-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Ensemble mean and bias with respect to E-OBS</a></span></li><li><span><a href=\"#Climate-change-signals\" data-toc-modified-id=\"Climate-change-signals-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Climate change signals</a></span></li><li><span><a href=\"#Time-series\" data-toc-modified-id=\"Time-series-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Time-series</a></span></li></ul></li><li><span><a href=\"#Technical-specifications\" data-toc-modified-id=\"Technical-specifications-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Technical specifications</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[next notebook](2022_Bano_DeepESD_GMD.ipynb)\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b> This notebook was run on a machine with the following technical specifications:\n",
    "\n",
    "- Operating system: Ubuntu 18.04.3 LTS (64 bits)\n",
    "- Memory: 60 GiB\n",
    "- Processor: 2x Intel(R) Xeon(R) CPU E5-2670 0 @ 2.60GHz (16 cores, 32 threads)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the R environment and working directories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is written in the free programming language `R` (version 3.6.1) and builds on [`climate4R`](https://doi.org/10.1016/j.envsoft.2018.09.009) (hereafter C4R), a suite of `R` packages developed by the Santander Meteorology Group for transparent climate data access, post processing (including bias correction and downscaling) and visualization. For details on C4R, the interested reader is referred to [Iturbide et al. 2019](https://doi.org/10.1016/j.envsoft.2018.09.009)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In particular, the following C4R libraries are used along the notebook:\n",
    "\n",
    "\n",
    " * `loadeR` (v1.7.0) for data loading,\n",
    " * `loadeR.2nc` (v0.1.1) for data loading, \n",
    " * `transformeR` (v2.1.0) for data manipulation, \n",
    " * [`downscaleR`](https://doi.org/10.5194/gmd-13-1711-2020) (v3.3.2) for downscaling and\n",
    " * [`downscaleR.keras`](https://doi.org/10.5194/gmd-13-2109-2020) (v1.0.0) for downscaling with neural networks and\n",
    " * `visualizeR` (v1.6.0) data visualization\n",
    " * `climate4R.UDG` (v0.2.3) datasets collection\n",
    " * `climate4R.value` (v0.0.2) VALUE indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To install them you may use the devtools package (e.g., ``devtools::install_github(\"SantanderMetGroup/downscaleR.keras@v1.0.0\")`` to install `downscaleR.keras`). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is highly recommended that you use the *conda* package and environment manager to install the entire C4R framework (C4R version 1.5.0), executing the following commands in your command shell terminal: \n",
    "```shell\n",
    "$ conda create --name climate4R\n",
    "$ conda activate climate4R\n",
    "$ conda install -c conda-forge -c r -c defaults -c santandermetgroup climate4r\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** \n",
    "**Note**: that even with C4R v1.5.0 installed via conda, you still need to upgrade libraries `climate4R.UDG` and `VALUE` with the `devtools` package by typing: \n",
    "```R\n",
    "> devtools::install_github(c(\"SantanderMetGroup/climate4R.UDG@v0.2.2\",\"SantanderMetGroup/VALUE@v2.2.2\"))\n",
    "```\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the libraries with the specific versions needed to replicate the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-19T21:10:13.881533Z",
     "start_time": "2022-05-19T21:10:11.793Z"
    }
   },
   "outputs": [],
   "source": [
    "options(java.parameters = \"-Xmx8g\")  # expanding Java memory\n",
    "\n",
    "# C4R libraries\n",
    "library(loadeR)\n",
    "library(loadeR.2nc)\n",
    "library(transformeR)\n",
    "library(downscaleR)\n",
    "library(downscaleR.keras) \n",
    "library(visualizeR)\n",
    "library(climate4R.value)\n",
    "\n",
    "# Other useful libraries\n",
    "library(magrittr)  # to pipe commands using '%>%' or '%<>%'\n",
    "\n",
    "# For visualization purposes\n",
    "library(RColorBrewer)\n",
    "library(gridExtra)\n",
    "library(ggplot2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intermediate data, predictions and models, generated along this notebook, are saved in a tree of directories created on the notebook's working directory. Please use the `dir.create` function to create two new directories (`data` and `models`) in your working directory. \n",
    "Within each of these directories, create subsequently two more subdirectories, named `tas` (near-surface temperature) and `pr` (precipitation) representing the respective predictands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-19T21:40:04.306134Z",
     "start_time": "2022-05-19T21:40:04.292Z"
    }
   },
   "outputs": [],
   "source": [
    "dir.create(\"./data/pr\", recursive = TRUE, showWarnings = FALSE)\n",
    "dir.create(\"./data/tas\", showWarnings = FALSE)\n",
    "dir.create(\"./models/pr\", recursive = TRUE, showWarnings = FALSE)\n",
    "dir.create(\"./models/tas\", showWarnings = FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, create also a *figures* directory in the working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-19T21:40:04.306134Z",
     "start_time": "2022-05-19T21:40:04.292Z"
    }
   },
   "outputs": [],
   "source": [
    "dir.create(\"./figures\", showWarnings = FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define here the **predictand** that will be used in the rest of the notebook. Predictor variables are defined in the next section, regardless of the predictand selected here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- define the predictand as 'pr' or 'tas' ---\n",
    "predictand <- 'pr' \n",
    "# ----------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and regrid data\n",
    "\n",
    "We are now ready to load into our `R` environment all the data we are going to work with. The table below lists the required datasets, available in netCDF format,  which can be obtained in two ways:\n",
    "* Access through the [Climate Data Service](http://meteo.unican.es/cds) developed by the [Santander Met Group](http://meteo.unican.es) (non registered users need to register first [here](http://meteo.unican.es/udg-tap/signup)). Use the `loginUDG` function to log into the service with your own credentials.\n",
    "* Point to the url associated to each dataset to download the netCDF from the original source."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Dataset/Label  | Data endpoint | License | Tracking id |\n",
    "|---|---|---|---|\n",
    "| ERA-Interim |  | | |\n",
    "| E-OBS v20e | https://surfobs.climate.copernicus.eu/dataaccess/access_eobs.php#datafiles | | |\n",
    "|CMIP5-subset_CanESM2_r1i1p1_historical |  | | |\n",
    "|CMIP5-subset_CNRM-CM5_r1i1p1_historical |  | | |\n",
    "|CMIP5-subset_MPI-ESM-MR_r1i1p1_historical |  | | |\n",
    "|CMIP5-subset_MPI-ESM-LR_r1i1p1_historical |  | | |\n",
    "|CMIP5-subset_NorESM1-M_r1i1p1_historical |  | | | \n",
    "|CMIP5-subset_GFDL-ESM2M_r1i1p1_historical |  | | |\n",
    "|CMIP5-subset_EC-EARTH_r12i1p1_historical |  | | |\n",
    "|CMIP5-subset_IPSL-CM5A-MR_r1i1p1_historical |  | | |\n",
    "|CMIP5-subset_CanESM2_r1i1p1_rcp85 |  | | |\n",
    "|CMIP5-subset_CNRM-CM5_r1i1p1_rcp85 |  | | |\n",
    "|CMIP5-subset_MPI-ESM-MR_r1i1p1_rcp85 |  | | |\n",
    "|CMIP5-subset_MPI-ESM-LR_r1i1p1_rcp85 |  | | |\n",
    "|CMIP5-subset_NorESM1-M_r1i1p1_rcp85 |  | | |\n",
    "|CMIP5-subset_GFDL-ESM2M_r1i1p1_rcp85 |  | | |\n",
    "|CMIP5-subset_EC-EARTH_r12i1p1_rcp85 |  | | |\n",
    "|CMIP5-subset_IPSL-CM5A-MR_r1i1p1_rcp85 |  | | |\n",
    "|CORDEX-EUR-44_CCCma-CanESM2_historical_r1i1p1_SMHI-RCA4_v1|  | | |\n",
    "|CORDEX-EUR-44_CNRM-CERFACS-CNRM-CM5_historical_r1i1p1_ETH-CLMcom-CCLM5-0-6_v1|  | | |\n",
    "|CORDEX-EUR-44_CNRM-CERFACS-CNRM-CM5_historical_r1i1p1_SMHI-RCA4_v1|  | | |\n",
    "|CORDEX-EUR-44_MPI-M-MPI-ESM-LR_historical_r1i1p1_CLMcom-CCLM4-8-17_v1|  | | |\n",
    "|CORDEX-EUR-44_MPI-M-MPI-ESM-LR_historical_r1i1p1_MPI-CSC-REMO2009_v1|  | | |\n",
    "|CORDEX-EUR-44_NCC-NorESM1-M_historical_r1i1p1_SMHI-RCA4_v1|  | | |\n",
    "|CORDEX-EUR-44_NOAA-GFDL-GFDL-ESM2M_historical_r1i1p1_SMHI-RCA4_v1|  | | |\n",
    "|CORDEX-EUR-44_ICHEC-EC-EARTH_historical_r12i1p1_SMHI-RCA4_v1|  | | |\n",
    "|CORDEX-EUR-44_ICHEC-EC-EARTH_historical_r12i1p1_ETH-CLMcom-CCLM5-0-6_v1|  | | |\n",
    "|CORDEX-EUR-44_IPSL-IPSL-CM5A-MR_historical_r1i1p1_SMHI-RCA4_v1|  | | |\n",
    "|CORDEX-EUR-44_IPSL-IPSL-CM5A-MR_historical_r1i1p1_IPSL-INERIS-WRF331F_v1|  | | |\n",
    "|CORDEX-EUR-44_CCCma-CanESM2_rcp85_r1i1p1_SMHI-RCA4_v1|  | | |\n",
    "|CORDEX-EUR-44_CNRM-CERFACS-CNRM-CM5_rcp85_r1i1p1_ETH-CLMcom-CCLM5-0-6_v1|  | | |\n",
    "|CORDEX-EUR-44_CNRM-CERFACS-CNRM-CM5_rcp85_r1i1p1_SMHI-RCA4_v1|  | | |\n",
    "|CORDEX-EUR-44_MPI-M-MPI-ESM-LR_rcp85_r1i1p1_CLMcom-CCLM4-8-17_v1|  | | |\n",
    "|CORDEX-EUR-44_MPI-M-MPI-ESM-LR_rcp85_r1i1p1_MPI-CSC-REMO2009_v1|  | | |\n",
    "|CORDEX-EUR-44_NCC-NorESM1-M_rcp85_r1i1p1_SMHI-RCA4_v1|  | | |\n",
    "|CORDEX-EUR-44_NOAA-GFDL-GFDL-ESM2M_rcp85_r1i1p1_SMHI-RCA4_v1|  | | |\n",
    "|CORDEX-EUR-44_ICHEC-EC-EARTH_rcp85_r12i1p1_SMHI-RCA4_v1|  | | |\n",
    "|CORDEX-EUR-44_ICHEC-EC-EARTH_rcp85_r12i1p1_ETH-CLMcom-CCLM5-0-6_v1|  | | |\n",
    "|CORDEX-EUR-44_IPSL-IPSL-CM5A-MR_rcp85_r1i1p1_SMHI-RCA4_v1|  | | |\n",
    "|CORDEX-EUR-44_IPSL-IPSL-CM5A-MR_rcp85_r1i1p1_IPSL-INERIS-WRF331F_v1|  | | |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once these data are downloaded, the following block of code allows for loading the ERA-Interim predictor variables, which are needed to train our neural networks, for the period 1979-2005 by using the `loadGridData` function. Subsequently, the `makeMultiGrid` creates a unique C4R object containing all this information. **Note that we exemplify the data load from UDG, but the same commands can load from local files by replacing the `dataset` argument by the path to local data**.  \n",
    "\n",
    "Moreover, since these loading steps can be quite time-consuming, we save the predictors `x` and predictand `y` data into R objects, which are also provided for reproducibility of the rest of the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "do.call(loginUDG, as.list(readLines(\"udg_login.txt\")))\n",
    "# or just:\n",
    "#loginUDG(\"user\",\"password\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "UDG.datasets(\"ECMWF_ERA-Interim-ESD\", full.info = TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-21T08:56:02.721148Z",
     "start_time": "2022-05-21T08:56:02.710Z"
    }
   },
   "outputs": [],
   "source": [
    "# Predictor variables considered (see -*-)\n",
    "vars  <- c(\n",
    "  \"psl\",                         # Pressure at surface level \n",
    "  \"z@500\",\"z@700\",\"z@850\",       # Geopotential height at isobaric levels\n",
    "  \"hus@500\",\"hus@700\",\"hus@850\", # Specific humidity at isobaric levels\n",
    "  \"ta@500\",\"ta@700\",\"ta@850\",    # Air temperature at isobaric levels\n",
    "  \"ua@500\",\"ua@700\",\"ua@850\",    # East-ward wind at isobaric levels \n",
    "  \"va@500\",\"va@700\",\"va@850\"     # North-ward wind at isobaric levels \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We loop over the variables and then use  makeMultiGrid,\n",
    "to bind the variables in a single C4R object.\n",
    "`ECMWF_ERA-Interim-ESD` is the path to the netCDFs \n",
    "of ERA-Interim-ESD downloaded from the endpoint \n",
    "indicated in the Table above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output.file = \"./data/x.rds.xz\"\n",
    "if (! file.exists(output.file)){\n",
    "  x <- lapply(vars, function(var) {\n",
    "    loadGridData(\n",
    "      dataset = \"ECMWF_ERA-Interim-ESD\",\n",
    "      var     = var,\n",
    "      lonLim  = c(-8,34), latLim  = c(34,76),  # domain of the predictors\n",
    "      years   = 1979:2005\n",
    "    )}\n",
    "  ) %>% makeMultiGrid()\n",
    "  saveRDS(x, output.file, compress=\"xz\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As predictands we use temperature and precipitation from E-OBS, which can be obtained as netCDF files [here](https://www.ecad.eu/download/ensembles/download.php).\n",
    "Once downloaded, these data can be imported in `R` with the `loadGridData` function.\n",
    "Subsequently, using `transformeR::interpGrid`, we upscale these E-OBS fields from their native 0.25º to the 0.5º regular grid our projections are delivered.\n",
    "We illustrate next how to load either precipitation or temperature with `loadGridData`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve E-OBS data if not available locally:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eobs.varname <- switch(predictand, pr = \"rr\", tas = \"tg\")\n",
    "eobs.data <- sprintf(\"./data/%s/%s_ens_mean_0.25deg_reg_v20.0e.nc\", predictand, eobs.varname)\n",
    "if (! file.exists(eobs.data)){\n",
    "  download.file(\n",
    "    sprintf(\"https://knmi-ecad-assets-prd.s3.amazonaws.com/ensembles/data/Grid_0.25deg_reg_ensemble/%s_ens_mean_0.25deg_reg_v20.0e.nc\", eobs.varname),\n",
    "    eobs.data\n",
    "  )\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upscale E-OBS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-19T20:34:11.212241Z",
     "start_time": "2022-05-19T20:34:11.195Z"
    }
   },
   "outputs": [],
   "source": [
    "# boundaries of our projections domain and target resolution\n",
    "grid05 = list(\"x\" = c(-9.75,30.25),\"y\" = c(34.25,74.25))\n",
    "attr(grid05,\"resX\") <- attr(grid05,\"resY\") <- 0.5 \n",
    "\n",
    "# Load the predictand (y) and save to file\n",
    "output.file = sprintf(\"./data/%s/y.rds.xz\", predictand)\n",
    "if (! file.exists(output.file)){\n",
    "  y <- loadGridData(\n",
    "    dataset = eobs.data,\n",
    "    var = eobs.varname,\n",
    "    lonLim = c(-10,30),\n",
    "    latLim = c(34,75),\n",
    "    years = 1979:2005\n",
    "  ) %>% interpGrid(new.coordinates = grid05, method = \"bilinear\")\n",
    "  saveRDS(y, output.file, compress=\"xz\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Neural Networks (CNNs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build *DeepESD* we rely on the convolutional neural networks (CNN) presented in [Baño-Medina et al. 2020](https://gmd.copernicus.org/articles/13/2109/2020/); in particular, on the CNN1 and CNN10 models, which were found to provide robust results for precipitation and temperature, respectively, both in ''perfect-prognosis'' conditions but also in the GCM space. The cell below shows how to build these CNN models based on `Keras`, and save them in a custom function called `modelCNN`. Note that precipitation and temperature CNN models are different. \n",
    "We refer the reader to [Baño-Medina et al. 2020](https://gmd.copernicus.org/articles/13/2109/2020/) for further details about the exact configuration of the CNNs used herein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-19T20:48:35.179232Z",
     "start_time": "2022-05-19T20:48:35.171Z"
    }
   },
   "outputs": [],
   "source": [
    "modelCNN <- function(inp) {\n",
    "  padding = switch(predictand, pr = \"same\", tas = \"valid\")\n",
    "  filters.l1 = 50\n",
    "  filters.l2 = 25\n",
    "  filters.l3 = switch(predictand, pr = 1, tas = 10)\n",
    "  # Input layer\n",
    "  inputs <- layer_input(shape = dim(inp$x.global)[2:4])\n",
    "  # Hidden layers\n",
    "  l1 = layer_conv_2d(inputs, filters = filters.l1, kernel_size = c(3,3), activation = 'relu', padding = padding)\n",
    "  l2 = layer_conv_2d(    l1, filters = filters.l2, kernel_size = c(3,3), activation = 'relu', padding = padding)\n",
    "  l3 = layer_conv_2d(    l2, filters = filters.l3, kernel_size = c(3,3), activation = 'relu', padding = padding)\n",
    "  l4 = layer_flatten(    l3)\n",
    "  # Output layer (depends on predictand)\n",
    "  if (predictand == \"pr\") {\n",
    "    l51 = layer_dense(l4, units = dim(inp$y$Data)[2], activation = 'sigmoid') \n",
    "    l52 = layer_dense(l4, units = dim(inp$y$Data)[2], activation = 'linear' ) \n",
    "    l53 = layer_dense(l4, units = dim(inp$y$Data)[2], activation = 'linear' ) \n",
    "    outputs <- layer_concatenate(list(l51,l52,l53))\n",
    "  } else if (predictand == \"tas\") {\n",
    "    l51 = layer_dense(l4, units = dim(inp$y$Data)[2], activation = 'linear') \n",
    "    l52 = layer_dense(l4, units = dim(inp$y$Data)[2], activation = 'linear') \n",
    "    outputs <- layer_concatenate(list(l51, l52)) \n",
    "  }\n",
    "  model <- keras_model(inputs = inputs, outputs = outputs) \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepESD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we 1) load the predictor variables of interest from the 8 GCM considered from the Santander CDS, 2) harmonize and standardize these predictor fields, 3) save these processed fields in `rda` objects to avoid repeating these steps in the future, 4) build the CNN models based on ERA-Interim predictors and E-OBS predictands and 5) apply these models to the GCM predictor variables to obtain the final high-resolution (downscaled at 0.5º) projections up to 2100."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the predictor datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following labels identify the 8 GCMs considered in this work in the Santander CDS, for the historical and RCP.8.5 scenario, respectively.\n",
    "These labels are used to build the dataset names when calling the `loadGridData` function for data loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-19T21:10:35.796755Z",
     "start_time": "2022-05-19T21:10:35.787Z"
    }
   },
   "outputs": [],
   "source": [
    "## Use UDG.datasets()$CMIP5_subset to obtain the labels of the desired GCMs\n",
    "model.names <- c(\n",
    "  \"CanESM2_r1i1p1\",\n",
    "  \"CNRM-CM5_r1i1p1\",\n",
    "  \"MPI-ESM-MR_r1i1p1\",\n",
    "  \"MPI-ESM-LR_r1i1p1\",\n",
    "  \"NorESM1-M_r1i1p1\",\n",
    "  \"GFDL-ESM2M_r1i1p1\",\n",
    "  \"EC-EARTH_r12i1p1\",\n",
    "  \"IPSL-CM5A-MR_r1i1p1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following loop allows us to load the predictors from the above GCMs over our target domain for the reference (1975-2005) and future (early-future: 2006-2040, mid-future: 2041-2070, far-future: 2071-2100) periods of interest. Note that the historical experiment is used for the reference period and the RCP8.5 scenario for the future periods. Note also that, within the loop, all GCMs are interpolated to the spatial resolution of the ERA-Interim predictors which were used to fit the CNNs. Once loaded, the GCM predictors are saved as `.rda` files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill850na <- function(x){\n",
    "  # Since the IPSL contains NA values in the 850hPa level at certain gridpoints,\n",
    "  # we replace these NA values with the numeric values of their closest neighbours.\n",
    "  ind850 <- grepl(\"@850\",x$Variable$varName,fixed = TRUE) %>% which()\n",
    "  indGP <- apply(x$Data[ind850[1],1,,,], MARGIN = c(2,3), anyNA) %>% which(arr.ind = TRUE)\n",
    "  for (i in 1:nrow(indGP)) {\n",
    "    indTime <- is.na(x$Data[ind850[1],1,,indGP[i,1],indGP[i,2]]) %>% which()\n",
    "    x$Data[ind850,1,indTime,indGP[i,1],indGP[i,2]] <- x$Data[ind850,1,indTime,indGP[i,1],indGP[i,2]-1]\n",
    "  }\n",
    "  return(x)\n",
    "}\n",
    "\n",
    "periods <- list(\n",
    "  hist = 1975:2005, # must appear as first entry (used as reference)\n",
    "  near = 2006:2040,\n",
    "  midf = 2041:2070,\n",
    "  farf = 2071:2100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for (period in names(periods)){\n",
    "  for (model.name in model.names) {\n",
    "    output.file <- sprintf(\"./data/x_%s_%s.rds.xz\",\n",
    "      period,\n",
    "      gsub(\"_.*\",\"\",model.name)\n",
    "    )\n",
    "    if (! file.exists(output.file)){\n",
    "      if (period == \"hist\"){\n",
    "        dataset.name <- sprintf(\"CMIP5-subset_%s_historical\", model.name)\n",
    "      } else {\n",
    "        dataset.name <- sprintf(\"CMIP5-subset_%s_rcp85\", model.name)\n",
    "      }\n",
    "      x.gcm <- lapply(vars, function(var) {\n",
    "        loadGridData(\n",
    "          dataset = dataset.name,\n",
    "          var = var,\n",
    "          lonLim = c(-8,34), latLim = c(34,76),\n",
    "          years = periods[[period]]\n",
    "        ) %>% interpGrid(new.coordinates = getGrid(x))\n",
    "      }) %>% makeMultiGrid()\n",
    "  \n",
    "      if (substr(model.name,1,4) == \"IPSL\") {\n",
    "        x.gcm <- fill850na(x.gcm)\n",
    "      }\n",
    "  \n",
    "      saveRDS(x.gcm, file = output.file, compress = \"xz\")\n",
    "    }\n",
    "  }  \n",
    "}  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following loop allows us to harmonize and standardize the GCM predictors loaded in the previous step to assure they reasonable resemble the ERA-Interim variables used to train the CNN models (note this is one of the key assumptions that are done in ''perfect-prognosis'' downscaling). For this harmonization+standardization step, which is different depending on the particular scenario of interest (the reader is referred again to [Baño-Medina et al. 2020](https://gmd.copernicus.org/articles/13/2109/2020/) for details about this process), the `scaleGrid` function from `transformeR` is used. The so-processed GCM predictors, wich will be used as inputs to the CNN models, are saved as `rda` files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "ref.period <- 1979:2005\n",
    "\n",
    "harmonize <- function(grid, base, ref){\n",
    "  scaleGrid(grid, \n",
    "    base = base,\n",
    "    ref = ref,\n",
    "    type = \"standardize\",\n",
    "    spatial.frame = \"gridbox\",\n",
    "    time.frame = \"monthly\"\n",
    "  ) \n",
    "}\n",
    "\n",
    "standardize <- function(grid, base){\n",
    "  scaleGrid(grid, \n",
    "    base = base,\n",
    "    ref = ref,\n",
    "    type = \"standardize\"\n",
    "  ) \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "for (model.name in model.names) {\n",
    "  model.basename <- gsub(\"_.*\",\"\",model.name)\n",
    "  for (period in names(periods)) {\n",
    "    raw.x <- loadRDS(sprintf(\"./data/x_%s_%s.rds.xz\", period, model.basename))\n",
    "    if (period == \"hist\") {\n",
    "      harmonize.base <- subsetGrid(raw.x, years = ref.period)\n",
    "      x.harm <- harmonize(raw.x, base = harmonize.base, ref = x)\n",
    "      standardize.base <- subsetGrid(x.harm, years = ref.period)\n",
    "    } else {\n",
    "      x.harm <- harmonize(raw.x, base = harmonize.base, ref = x)\n",
    "    }\n",
    "    xn <- standardize(x.harm, base = standardize.base)\n",
    "    # Save the standardized predictor fields as `rda` objects  \n",
    "    saveRDS(xn,\n",
    "      file = sprintf(\"./data/xn_%s_%s.rds.xz\", period, gsub(\"_.*\",\"\",model.name)),\n",
    "      compress=\"xz\"\n",
    "    )\n",
    "    rm(xn)\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Neural Networks (CNNs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build *DeepESD* we rely on the convolutional neural networks (CNN) presented in [Baño-Medina et al. 2020](https://gmd.copernicus.org/articles/13/2109/2020/); in particular, on the CNN1 and CNN10 models, which were found to provide robust results for precipitation and temperature, respectively, both in ''perfect-prognosis'' conditions but also in the GCM space. The cell below shows how to build these CNN models based on `Keras`, and save them in a custom function called `modelCNN`. Note that precipitation and temperature CNN models are different. \n",
    "We refer the reader to [Baño-Medina et al. 2020](https://gmd.copernicus.org/articles/13/2109/2020/) for further details about the exact configuration of the CNNs used herein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-19T20:48:35.179232Z",
     "start_time": "2022-05-19T20:48:35.171Z"
    }
   },
   "outputs": [],
   "source": [
    "modelCNN <- function(inp) {\n",
    "  padding = switch(predictand, pr = \"same\", tas = \"valid\")\n",
    "  filters.l1 = 50\n",
    "  filters.l2 = 25\n",
    "  filters.l3 = switch(predictand, pr = 1, tas = 10)\n",
    "  # Input layer\n",
    "  inputs <- layer_input(shape = dim(inp$x.global)[2:4])\n",
    "  # Hidden layers\n",
    "  l1 = layer_conv_2d(inputs, filters = filters.l1, kernel_size = c(3,3), activation = 'relu', padding = padding)\n",
    "  l2 = layer_conv_2d(    l1, filters = filters.l2, kernel_size = c(3,3), activation = 'relu', padding = padding)\n",
    "  l3 = layer_conv_2d(    l2, filters = filters.l3, kernel_size = c(3,3), activation = 'relu', padding = padding)\n",
    "  l4 = layer_flatten(    l3)\n",
    "  # Output layer (depends on predictand)\n",
    "  if (predictand == \"pr\") {\n",
    "    l51 = layer_dense(l4, units = dim(inp$y$Data)[2], activation = 'sigmoid') \n",
    "    l52 = layer_dense(l4, units = dim(inp$y$Data)[2], activation = 'linear' ) \n",
    "    l53 = layer_dense(l4, units = dim(inp$y$Data)[2], activation = 'linear' ) \n",
    "    outputs <- layer_concatenate(list(l51,l52,l53))\n",
    "  } else if (predictand == \"tas\") {\n",
    "    l51 = layer_dense(l4, units = dim(inp$y$Data)[2], activation = 'linear') \n",
    "    l52 = layer_dense(l4, units = dim(inp$y$Data)[2], activation = 'linear') \n",
    "    outputs <- layer_concatenate(list(l51, l52)) \n",
    "  }\n",
    "  model <- keras_model(inputs = inputs, outputs = outputs) \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downscaling\n",
    "\n",
    "This section shows how to fit the CNN model which links the large-scale predictors from ERA-Interim with the high-resolution E-OBS precipitation or temperature. The steps would be:\n",
    "- Prepare the predictor and predictand tensors with the `prepareData.keras` function from `downscaleR.keras`.\n",
    "- Standardize the ERA-Interim predictors using `trasformeR::scaleGrid`. \n",
    "- For precipitation, for a better fit of the Gamma distribution, 0.99 is substracted from observed precipitation and negative values are ignored (note that this step implies that rainy days are defined as those receiving 1 or more mm of precipitation). To do this, the `gridArithmetics` and `binaryGrid` functions from `transformeR` are used.\n",
    "- Train the CNN model encapsulaled in the `modelCNN` function (previously defined) with the `downscaleTrain.keras` function from `downscaleR.keras`. To optimize the negative log-likelihood of the Bernoulli-Gamma distribution, we employ the custom loss function `bernouilliGammaLoss` from `downscaleR.keras`. The network is fitted using the Adam optimizer and a learning rate of 1e-4. Early-stopping with a patience of 30 epochs is applied and the best model (epoch) is saved in the working directory as a `.h5` file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the reanalysis predictors and observed predictand saved previously:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-19T22:06:48.755707Z",
     "start_time": "2022-05-19T22:06:44.431Z"
    }
   },
   "outputs": [],
   "source": [
    "x <- readRDS(\"./data/x.rds.xz\")\n",
    "y <- readRDS(sprintf(\"./data/%s/y.rds.xz\", predictand))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardize them depending on the target variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-19T22:08:33.170840Z",
     "start_time": "2022-05-19T22:08:08.578Z"
    }
   },
   "outputs": [],
   "source": [
    "x <- scaleGrid(x,type = \"standardize\")\n",
    "if (predictand == \"pr\"){\n",
    "  y <- binaryGrid(\n",
    "    gridArithmetics(y, 0.99, operator = \"-\"),\n",
    "    condition = \"GE\",\n",
    "    threshold = 0,\n",
    "    partial = TRUE\n",
    "  )\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-19T22:09:53.354271Z",
     "start_time": "2022-05-19T22:09:50.559Z"
    }
   },
   "source": [
    "Prepare predictor and predictand data for downscaling with `downscaleR.keras`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-19T22:09:53.354271Z",
     "start_time": "2022-05-19T22:09:50.559Z"
    }
   },
   "outputs": [],
   "source": [
    "xy.train <- prepareData.keras(\n",
    "  x = x,\n",
    "  y = y,\n",
    "  first.connection = \"conv\",\n",
    "  last.connection = \"dense\",\n",
    "  channels = \"last\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And train the model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Warning:</b>\n",
    "Running the next cell takes about 1 hour\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-19T22:25:23.039623Z",
     "start_time": "2022-05-19T22:25:23.029Z"
    }
   },
   "outputs": [],
   "source": [
    "cnnmodel.name <- switch(predictand,\n",
    "  pr=\"CNN1\",\n",
    "  tas=\"CNN10\"\n",
    ")\n",
    "cnnloss <- switch(predictand,\n",
    "  pr = bernouilliGammaLoss(last.connection = \"dense\"),\n",
    "  tas = gaussianLoss(last.connection = \"dense\")\n",
    ")\n",
    "\n",
    "output.file <- sprintf('./models/%s/%s.h5', predictand, cnnmodel.name)\n",
    "if (! file.exists(output.file)){\n",
    "\n",
    "  # Training the CNN model\n",
    "  downscaleTrain.keras(\n",
    "    obj = xy.train, \n",
    "    model = modelCNN(xy.train),\n",
    "    clear.session = TRUE,\n",
    "    compile.args = \n",
    "      list(\n",
    "        \"loss\" = cnnloss,\n",
    "        \"optimizer\" = optimizer_adam(lr = 0.0001)\n",
    "      ),\n",
    "    fit.args =\n",
    "      list(\n",
    "        \"batch_size\" = 100,\n",
    "        \"epochs\" = 10000,\n",
    "        \"validation_split\" = 0.1,\n",
    "        \"verbose\" = 1,\n",
    "        \"callbacks\" = list(\n",
    "           callback_early_stopping(patience = 30),\n",
    "           callback_model_checkpoint(\n",
    "             filepath = output.file,\n",
    "             monitor = 'val_loss',\n",
    "             save_best_only = TRUE\n",
    "           )\n",
    "        )\n",
    "     )\n",
    "  )\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the model is trained, we use it to predict in both the train (training period using ERA-Interim variables) and the GCM spaces. As per the former, for precipitation, we are interested in the estimation of the parameter `p` (probability of rain), since it is needed later to adjust the frequency of rain in the high-resolution projections obtained from the GCM (see the manuscript for details)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute `p` in the train period the following is done:\n",
    "- Prepare the predictors which will serve as inputs for the CNN model with the `prepareNewData.keras` function. Subsequently, use them to predict in the train set with the `downscalePredict.keras` function. The `model` argument indicates the path where the CNN model was previously stored, and `C4Rtemplate` is a C4R object used as template for the predictions which provides the proper metadata. Since `downscalePredict.keras` outputs 3 parameters (the probability of rain, `p`, and the logarithmic of the shape and scale parameters of the Gamma distribution, `log_alpha` and `log_beta`), the `subsetGrid` is applied in order to keep only `p`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-19T22:27:10.039623Z",
     "start_time": "2022-05-19T22:27:06.438Z"
    }
   },
   "outputs": [],
   "source": [
    "cnnloss.name <- switch(predictand,\n",
    "  pr = \"bernouilliGammaLoss\",\n",
    "  tas = \"gaussianLoss\"\n",
    ")\n",
    "\n",
    "cnn.predict <- function(newdata){\n",
    "  downscalePredict.keras(\n",
    "    newdata = newdata,\n",
    "    C4R.template = y,\n",
    "    clear.session = TRUE,\n",
    "    loss = cnnloss.name,\n",
    "    model = list(\n",
    "      \"filepath\" = sprintf('./models/%s/%s.h5', predictand, cnnmodel.name),\n",
    "      \"custom_objects\" = c(\n",
    "          \"custom_loss\" = cnnloss\n",
    "      )\n",
    "    )\n",
    "  )  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-19T22:27:10.039623Z",
     "start_time": "2022-05-19T22:27:06.438Z"
    }
   },
   "outputs": [],
   "source": [
    "if (predictand == \"pr\"){\n",
    "  xy.test <- prepareNewData.keras(x, xy.train)\n",
    "  pred_ocu_train <- cnn.predict(xy.test) %>% subsetGrid(var = \"p\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, the trained CNN model is used to generate the high-resolution projections building on the 8 GCMs considered in this work. To do so, we perform a loop over the GCMs in which the corresponding predictors (which had been previously saved) are loaded and conveniently transformed using the `prepareNewData.keras` function. Finally, the `log_alpha`, `log_beta` and `p` parameters, which are obtained with the `downscalePredict.keras` function are saved in the `pred` object.\n",
    "- On the one hand, `log_alpha` and `log_beta` are used to obtain the rainfall amount with the `computeRainfall` function from `downscaleR.keras`. The argument `simulate` allows us for specifying if either a stochastic or a deterministic outcome is wanted. The argument `bias` is used to re-center the Gamma distribution to 1mm/day. \n",
    "- On the other hand, we use the `p` parameter to derive the binary event occurrence/non occurrence through the `bynaryGrid` function.\n",
    "- Finally, both series (binary and continuous) are multiplied to produce the complete precipitation time series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following block of code we define commodity functions to compute the (deterministic) frequency and (stochastic) amount of rain, or the deterministic temperature value (as the mean of the predicted distribution). Then we iterate to predict (downscale) for all models, which are saved in `.nc` format with the `grid2nc` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict.pr <- function(pred.obj){\n",
    "  # Deterministic frequency and stochastic amount of rain\n",
    "  computeRainfall(\n",
    "    log_alpha = subsetGrid(pred.obj, var = \"log_alpha\"),\n",
    "    log_beta  = subsetGrid(pred.obj, var = \"log_beta\"),\n",
    "    bias = 1,\n",
    "    simulate = TRUE\n",
    "  ) %>% gridArithmetics(\n",
    "    binaryGrid(\n",
    "      subsetGrid(pred.obj, var = \"p\"),\n",
    "      ref.obs = binaryGrid(y, threshold = 1, condition = \"GE\"),\n",
    "      ref.pred = pred_ocu_train\n",
    "    )\n",
    "  )  \n",
    "}\n",
    "\n",
    "predict.tas <- function(pred.obj){\n",
    "  ## Deterministic version \n",
    "  rval <- subsetGrid(pred.obj, var = \"mean\")\n",
    "  rval$Variable$varName <- \"tas\"\n",
    "  return(rval)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Warning:</b>\n",
    "Running the next cell takes hours\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (model.name in model.names) {\n",
    "  model.basename <- gsub(\"_.*\",\"\",model.name)    \n",
    "  for (period in names(periods)) {\n",
    "    xn <- loadRDS(sprintf(\"./data/xn_%s_%s.rds.xz\", period, model.basename))\n",
    "    xy.test <- prepareNewData.keras(xn, xy.train)\n",
    "    pred <- cnn.predict(xy.test)\n",
    "    pred.params <- switch(predictor,\n",
    "      pr = predict.pr(pred),\n",
    "      tas = predict.tas(pred)\n",
    "    ) \n",
    "    grid2nc(pred.params, NetCDFOutFile = sprintf(\"./data/%s/y_CNN_%s_%s.nc4\", period, model.basename))   \n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamical climate models\n",
    "To assess the credibility of DeepESD, it is compared against two different ensembles of dynamical models (see the *Technical Validation* section), the first/second of them formed by Global/Regional Climate Models (GCMs/RCMs). Since DeepESD covers only land, we start by creating a 0.5º land-sea mask which will be later applied to eliminate sea points from both GCMs and RCMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.file <- \"./data/mask.nc4\"\n",
    "if (! file.exists(output.file)){\n",
    "\n",
    "  y = readRDS(\"./data/pr/y.rds.xz\")\n",
    "  mask <- gridArithmetics(subsetGrid(y, year = 1990), 0) %>% gridArithmetics(1, operator = \"+\") %>% climatology()\n",
    "  mask$Variable$varName <- \"sftlf\"\n",
    "  grid2nc(mask, NetCDFOutFile = output.file)\n",
    "\n",
    "} else{\n",
    "    \n",
    "  mask <- loadGridData(output.file, var = \"sftlf\")\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble of Global Climate Models (GCMs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perform a loop over the temporal periods of interest (1975-2005 for the historical scenario plus 2006-2040, 2041-2070 and 2071-2100 for RCP8.5) and save the GCM ensemble as netCDF files (`grid2nc` function) in a multi-member C4R object. All GCMs are interpolated to our target 0.5º resolution (E-OBS grid), using conservative remapping. To do this interpolation, we rely on the `cdo` library and use function `system` to invoke the OS command. Please note that you can install the `cdo` library with conda, by typing `conda install cdo` in a terminal. Finally, sea points are removed by applying the land-sea mask we have previously created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-19T21:11:26.309149Z",
     "start_time": "2022-05-19T21:11:25.249Z"
    }
   },
   "outputs": [],
   "source": [
    "cdo.conservative.remap <- function(grid){\n",
    "  grid2nc(grid, NetCDFOutFile = \"./aux.nc4\")\n",
    "  system(\"cdo remapcon,data/mask.nc4 ./aux.nc4 ./aux2.nc4\")\n",
    "  rval <- loadGridData(\"./aux2.nc4\", var = predictand)\n",
    "  file.remove(c(\"./aux.nc4\",\"./aux2.nc4\"))\n",
    "  return(rval)\n",
    "}\n",
    "\n",
    "mask.landsea <- function(grid){\n",
    "  lapply(1:getShape(grid, \"time\"), function(t) {\n",
    "    gridArithmetics(\n",
    "      subsetDimension(grid, dimension = \"time\", indices = t),\n",
    "      mask\n",
    "    )\n",
    "  }) %>% bindGrid(dimension = \"time\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-19T21:11:26.309149Z",
     "start_time": "2022-05-19T21:11:25.249Z"
    }
   },
   "outputs": [],
   "source": [
    "for (period in names(periods)){\n",
    "  for (model.name in model.names) {\n",
    "    output.file <- sprintf(\"./data/%s/y_GCM_%s_%s.nc4\",\n",
    "      predictand,\n",
    "      period,\n",
    "      gsub(\"_.*\",\"\",model.name)\n",
    "    )\n",
    "    if (! file.exists(output.file)){\n",
    "      if (period == \"hist\"){\n",
    "        dataset.name <- sprintf(\"CMIP5-subset_%s_historical\", model.name)\n",
    "      } else {\n",
    "        dataset.name <- sprintf(\"CMIP5-subset_%s_rcp85\", model.name)\n",
    "      }\n",
    "      # Load the data and interpolate to the target resolution\n",
    "      y.gcm <- cdo.conservative.remap(loadGridData(\n",
    "          dataset = dataset.name,\n",
    "          var = predictand,\n",
    "          lonLim = c(-10,30), latLim = c(34,74),\n",
    "          years = periods[[period]]\n",
    "      ))\n",
    "      y.gcm <- mask.landsea(y.gcm)\n",
    "      grid2nc(y.gcm,NetCDFOutFile = output.file)\n",
    "    }\n",
    "  }  \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble of Regional Climate Models (RCMs) \n",
    "In this section we form an ensemble of EURO-CORDEX RCMs which can be easily loaded from the Santander CDS by using the appropiate labels (see the block below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-19T21:12:10.962579Z",
     "start_time": "2022-05-19T21:12:10.952Z"
    }
   },
   "outputs": [],
   "source": [
    "# Labels for the historical scenario\n",
    "rcm.labels.hist <- c(\n",
    "  \"CORDEX-EUR-44_CCCma-CanESM2_historical_r1i1p1_SMHI-RCA4_v1\",\n",
    "  \"CORDEX-EUR-44_CNRM-CERFACS-CNRM-CM5_historical_r1i1p1_ETH-CLMcom-CCLM5-0-6_v1\",\n",
    "  \"CORDEX-EUR-44_CNRM-CERFACS-CNRM-CM5_historical_r1i1p1_SMHI-RCA4_v1\",\n",
    "  \"CORDEX-EUR-44_MPI-M-MPI-ESM-LR_historical_r1i1p1_CLMcom-CCLM4-8-17_v1\",\n",
    "  \"CORDEX-EUR-44_MPI-M-MPI-ESM-LR_historical_r1i1p1_MPI-CSC-REMO2009_v1\",\n",
    "  \"CORDEX-EUR-44_NCC-NorESM1-M_historical_r1i1p1_SMHI-RCA4_v1\",\n",
    "  \"CORDEX-EUR-44_NOAA-GFDL-GFDL-ESM2M_historical_r1i1p1_SMHI-RCA4_v1\",\n",
    "  \"CORDEX-EUR-44_ICHEC-EC-EARTH_historical_r12i1p1_SMHI-RCA4_v1\",\n",
    "  \"CORDEX-EUR-44_ICHEC-EC-EARTH_historical_r12i1p1_ETH-CLMcom-CCLM5-0-6_v1\",\n",
    "  \"CORDEX-EUR-44_IPSL-IPSL-CM5A-MR_historical_r1i1p1_SMHI-RCA4_v1\",\n",
    "  \"CORDEX-EUR-44_IPSL-IPSL-CM5A-MR_historical_r1i1p1_IPSL-INERIS-WRF331F_v1\"\n",
    ")\n",
    "\n",
    "get.rcm.simulation.id <- function(x){\n",
    "  gcm <- unlist(strsplit(x,\"_\"))[2]\n",
    "  gcm <- unlist(strsplit(gcm,\"-\"))[-1]\n",
    "  if (gcm[[1]] %in% c(\"M\", \"CERFACS\", \"GFDL\")) # Drop modelling center remnants\n",
    "    gcm <- gcm[-1]\n",
    "  gcm <- paste(gcm, collapse=\"-\")\n",
    "  rcm <- unlist(strsplit(x,\"_\"))[5]\n",
    "  rcm <- unlist(strsplit(rcm,\"-\"))[-1]\n",
    "  if (rcm[[1]] %in% c(\"INERIS\", \"CLMcom\", \"CSC\")) # Drop modelling center remnants\n",
    "    rcm <- rcm[-1]\n",
    "  rcm <- paste(rcm, collapse=\"-\")\n",
    "  sprintf(\"%s_%s\", gcm, rcm)\n",
    "}\n",
    "\n",
    "# e.g.:\n",
    "get.rcm.simulation.id(rcm.labels.hist[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perfrom a loop over the temporal periods of interest (1975-2005 for the historical scenario plus 2006-2040, 2041-2070 and 2071-2100 for RCP8.5) and save the RCM ensemble as netCDF files (`grid2nc` function) in a multi-member C4R object. All RCMs are interpolated to our target 0.5º resolution (E-OBS grid) and sea points are removed by applying the land-sea mask we have previously created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for (period in names(periods)){\n",
    "  for (dataset.name in rcm.labels.hist) {\n",
    "    output.file <- sprintf(\"./data/%s/y_RCM_%s_%s.nc4\",\n",
    "      predictand,\n",
    "      period,\n",
    "      get.rcm.simulation.id(dataset.name)\n",
    "    )\n",
    "    if (! file.exists(output.file)){\n",
    "      if (! period == \"hist\"){\n",
    "        dataset.name <- gsub(\"historical\",\"rcp85\", dataset.name)\n",
    "      }\n",
    "      # Load the data and interpolate to the target resolution\n",
    "      y.rcm <- loadGridData(\n",
    "          dataset = dataset.name,\n",
    "          var = predictand,\n",
    "          lonLim = c(-10,30), latLim = c(34,74),\n",
    "          years = periods[[period]]\n",
    "      ) %>% interpGrid(getGrid(mask))\n",
    "      y.rcm <- mask.landsea(y.rcm)  \n",
    "      grid2nc(y.rcm,NetCDFOutFile = output.file)\n",
    "    }\n",
    "  }  \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section provides the code needed to reproduce the figures presented in the manuscript. Note we mostly rely on the `visualizeR` package for plotting since it supports both spatial maps and temporal series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble mean and bias with respect to E-OBS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 1 in the manuscript shows the climatology of the different ensembles built (GCM, RCM and DeepESD), along with the corresponding mean error (bias) with respect to the observed pattern in the historical period. We start thus by computing the climatology of the different contributing members forming each ensemble and saving them as netCDF files in the working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-19T21:12:30.621694Z",
     "start_time": "2022-05-19T21:12:30.600Z"
    }
   },
   "outputs": [],
   "source": [
    "# because a member of the RCM ensemble misses a value on 01-Jan-2006, so to preserve\n",
    "# temporal consistency in the ensemble we add this date to the ensemble mean metadata\n",
    "near.dates <- list(\n",
    "  start = \"2006-01-01 12:00:00 GMT\",\n",
    "    end = \"2041-01-01 12:00:00 GMT\"\n",
    ")\n",
    "model.types <- c(\"GCM\",\"RCM\",\"CNN\")\n",
    "gcm.basenames <- gsub(\"_.*\",\"\",model.names)\n",
    "rcm.basenames <- unlist(lapply(rcm.labels.hist, get.rcm.simulation.id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (model.type in model.types){\n",
    "  basenames = ifelse(model.type == \"RCM\", rcm.basenames, gcm.basenames)\n",
    "  for (period in names(periods)){\n",
    "    output.file <- sprintf(\"./data/%s/y_%s_%s_ensemble.nc4\", predictand, model.type, period)\n",
    "    if (! file.exists(output.file)){\n",
    "\n",
    "      ens.mean <- lapply(basenames, FUN = function(basename) {\n",
    "        path <- sprintf(\"./data/%s/y_%s_%s_%s.nc4\", predictand, model.type, period, basename)\n",
    "        grid <- loadGridData(dataset = path, var = predictand)\n",
    "        grid <- valueIndex(grid, index.code = \"Mean\")$Index  # compute mean of each member \n",
    "        if (period == \"near\") grid$Dates <- near.dates \n",
    "        return(grid)  \n",
    "      }) %>% bindGrid(dimension = \"member\")  # bind member means in a single C4R object along the `member` dimension    \n",
    "      ens.mean$InitializationDates <- NULL\n",
    "      grid2nc(ens.mean, NetCDFOutFile = output.file)\n",
    "        \n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the mean climatology for each ensemble is obtained with the `aggregateGrid` function (note the aggregation is done along the member dimension) from `transformeR`. Afterwards, we can already use `spatialPlot` to plot the corresponding spatial pattern. The resulting figure is saved in `pdf` format in the path indicated in the `pdfOutput` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-19T20:44:05.553453Z",
     "start_time": "2022-05-19T20:44:05.520Z"
    }
   },
   "outputs": [],
   "source": [
    "if (predictand == \"pr\") {\n",
    "  palette <- \"BuPu\"\n",
    "  at <- seq(0,8,0.5)\n",
    "  units <- \"mm/day\"\n",
    "} else if (predictand == \"tas\") {\n",
    "  palette <- \"OrRd\"\n",
    "  at <- seq(-5, 20,2.5)\n",
    "  units <- \"ºC\"\n",
    "}\n",
    "\n",
    "cb <- c(\"#FFFFFF\",brewer.pal(n = 9, palette))\n",
    "cb <- cb %>% colorRampPalette()\n",
    "pdfOutput <- sprintf(\"./figures/ensembleMean_%s.pdf\" , predictand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-21T09:32:22.399749Z",
     "start_time": "2022-05-21T09:32:22.386Z"
    }
   },
   "outputs": [],
   "source": [
    "nn <- c(\"GCM\",\"RCM\",\"CNN\")\n",
    "figs <- lapply(1:length(nn), FUN = function(z) {\n",
    "  \n",
    "  # We store in `grid` object the ensemble of climatologies  \n",
    "  grid <- loadGridData(paste0(\"./data/\", predictand, \"/\", nn[z], \"_h_ensemble.nc4\"), var = \"Mean\")\n",
    "  \n",
    "  # Compute the ensemble mean  \n",
    "  gridMean <-  aggregateGrid(grid,aggr.mem = list(FUN = \"mean\", na.rm = TRUE)) \n",
    "  \n",
    "  # We depict the ensemble mean with spatialPlot function  \n",
    "  spatialPlot(\n",
    "    gridMean,\n",
    "    backdrop.theme = \"coastline\",\n",
    "    main = paste0(\"Ensemble Mean (\",units,\") - \",nn[z]),\n",
    "    ylab = \"1975-2005\",\n",
    "    col.regions = cb,\n",
    "    at = at,\n",
    "    set.min = at[1], \n",
    "    set.max = at[length(at)])\n",
    "})\n",
    "\n",
    "pdf(pdfOutput, width = 15, height = 10)   \n",
    "grid.arrange(grobs = figs, ncol = 3)                     \n",
    "dev.off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we plot the bias with respecto to the observed (i.e. E-OBS) climatology. Again, we rely on `spatialPlot` to depict the spatial fields, and `aggregateGrid` and `gridArithmetics`, to compute the ensemble mean and its bias, respectively. The resulting figures are saved in `pdf` format in the path indicated by `pdfOutput`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-19T20:44:34.601831Z",
     "start_time": "2022-05-19T20:44:33.252Z"
    }
   },
   "outputs": [],
   "source": [
    "## Please select one:   -----------------------------------------------------------------------\n",
    "# Precipitation\n",
    "cb <- brewer.pal(n = 11, \"BrBG\")\n",
    "cb[6] <- \"#FFFFFF\"; cb <- cb %>% colorRampPalette()\n",
    "at <- c(seq(-2, -0.5,0.5),-0.25,0.25,seq(0.5, 2,0.5))    \n",
    "units <- \"mm/day\"\n",
    "pdfOutput <- \"./figures/bias_pr.pdf\" \n",
    "var <- \"precip\"\n",
    "load(\"./data/pr/y.rda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-19T20:44:36.092757Z",
     "start_time": "2022-05-19T20:44:34.296Z"
    }
   },
   "outputs": [],
   "source": [
    "# Temperature\n",
    "cb <- rev(brewer.pal(n = 11, \"RdBu\"))\n",
    "cb[6] <- \"#FFFFFF\"; cb <- cb %>% colorRampPalette()\n",
    "at <- c(seq(-2, -0.5,0.5),-0.25,0.25, seq(0.5,2,0.5)) \n",
    "units <- \"ºC\"\n",
    "pdfOutput <- \"./figures/bias_tas.pdf\"\n",
    "var <- \"temperature\"\n",
    "load(\"./data/tas/y.rda\")\n",
    "## --------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-19T20:45:16.782016Z",
     "start_time": "2022-05-19T20:44:39.381Z"
    }
   },
   "outputs": [],
   "source": [
    "nn <- c(\"GCM\",\"RCM\",\"CNN\")\n",
    "figs <- lapply(1:length(nn), FUN = function(z) {\n",
    "  # Compute the ensemble mean  \n",
    "  grid <- loadGridData(paste0(\"./data/\",var,\"/\",nn[z],\"_h_ensemble.nc4\"), var = \"Mean\") %>% aggregateGrid(aggr.mem = list(FUN = \"mean\", na.rm = TRUE))\n",
    "  # Compute the bias with respect to the observed temporal climatology for the same period\n",
    "  grid  %<>% gridArithmetics(valueIndex(y, index.code = \"Mean\")$Index,operator = \"-\")\n",
    "  # Depict the bias of the ensemble mean\n",
    "  spatialPlot(grid,\n",
    "              backdrop.theme = \"coastline\",\n",
    "              main = paste0(\"Bias Ensemble Mean (\",units,\") - \",nn[z]),\n",
    "              ylab = \"1975-2005\",\n",
    "              col.regions = cb,\n",
    "              at = at,\n",
    "              set.min = at[1], set.max = at[length(at)])  \n",
    "}) \n",
    "pdf(pdfOutput, width = 15, height = 10)   \n",
    "grid.arrange(grobs = figs, ncol = 3)                     \n",
    "dev.off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Climate change signals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To produce Figure 2 in the manuscript we perform a loop, for each ensemble (GCM, RCM and DeepESD), over the different RCP8.5 periods of interest and sequentially compute the difference between the future climatology and the historical one. These climate change signals are then averaged along the member dimension using the `aggregateGrid` function. The resulting figures are saved in `pdf` format in the path indicated by `pdfOutput`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Please select one:   -----------------------------------------------------------------------\n",
    "# Precipitation\n",
    "cb <- brewer.pal(n = 11, \"BrBG\")\n",
    "cb[6] <- \"#FFFFFF\"; cb <- cb %>% colorRampPalette()\n",
    "at <- c(seq(-1, -0.25,0.25),-0.125,0.125,seq(0.25, 1,0.25)) \n",
    "pdfOutput <- \"./figures/deltas_pr.pdf\" \n",
    "var <- \"precip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temperature\n",
    "cb <- c(\"#FFFFFF\",brewer.pal(n = 11, \"OrRd\"))\n",
    "at <- c(seq(0,4,0.5),5,6)\n",
    "pdfOutput <- \"./figures/deltas_tas.pdf\"\n",
    "var <- \"temperature\"\n",
    "## --------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn <- c(\"GCM\",\"RCM\",\"CNN\")\n",
    "figs <- lapply(c(\"ef\",\"mf\",\"ff\"), FUN = function(z) {  \n",
    "    lapply(1:length(nn), FUN = function(zz) {\n",
    "    gridh <- loadGridData(paste0(\"./data/\",var,\"/\",nn[zz],\"_h_ensemble.nc4\"), var = \"Mean\") \n",
    "    gridf <- loadGridData(paste0(\"./data/\",var,\"/\",nn[zz],\"_\",z,\"_ensemble.nc4\"), var = \"Mean\") \n",
    "    grid <- gridArithmetics(gridf,gridh,operator = \"-\")\n",
    "    gridMean <-  aggregateGrid(grid,aggr.mem = list(FUN = \"mean\", na.rm = TRUE)) \n",
    "\n",
    "    if (z == \"ef\") period <- c(\"2006-2040\")\n",
    "    if (z == \"mf\") period <- c(\"2041-2070\")\n",
    "    if (z == \"ff\") period <- c(\"2071-2100\")\n",
    "    spatialPlot(gridMean,\n",
    "                backdrop.theme = \"coastline\",\n",
    "                main = paste(\"CC. signal wrt 1975-2005\"),\n",
    "                ylab = period,\n",
    "                col.regions = cb,\n",
    "                at = at,\n",
    "                set.min = at[1], set.max = at[length(at)])  \n",
    "  }) \n",
    "}) %>% unlist(recursive = FALSE)   \n",
    "pdf(pdfOutput, width = 15, height = 10)   \n",
    "grid.arrange(grobs = figs, ncol = 3)                     \n",
    "dev.off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time-series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following block of code allows for plotting the time-series of the climate change signals. For precipitation (temperature), we perform a loop over the validation metrics of interest: R01, SDII (Mean). For details about these metrics please see the manuscript or type `show.indices()` in a new cell. At each iteration of the loop we define a `doCall.args` list which contains the `aggr.y` arguments needed for the `aggregateGrid` function (note the validation is done at an annual basis), which is finally passed t  `do.call`. At the end of the loop, the resulting figures are saved in `pdf` format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Please select one:   -----------------------------------------------------------------------\n",
    "# Precipitation\n",
    "indices <- c(\"R01\",\"SDII\")\n",
    "variable  <- \"precip\"\n",
    "var <- \"pr\"\n",
    "load(\"./data/pr/y.rda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temperature\n",
    "indices <- c(\"Mean\")\n",
    "variable <- \"temperature\"\n",
    "var <- \"tas\"\n",
    "load(\"./data/tas/y.rda\")\n",
    "## --------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dName <- c(\"CanESM2\",\"CNRM-CM5\",\"MPI-ESM-MR\",\"MPI-ESM-LR\",\"NorESM1\",\"GFDL\",\"EC-Earth\",\"IPSL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figs <- lapply(indices, FUN = function(zz) {\n",
    "  doCall.args <- list() \n",
    "  doCall.args[[\"aggr.y\"]] <- list()\n",
    "  \n",
    "  # The R01 do.call arguments  \n",
    "  if (zz == \"R01\")  {\n",
    "    doCall.args[[\"aggr.y\"]][[\"FUN\"]] <- \"index.freq\"\n",
    "    doCall.args[[\"aggr.y\"]][[\"freq.type\"]] <- \"rel\"\n",
    "    doCall.args[[\"aggr.y\"]][[\"condition\"]] <- \"GE\"\n",
    "    doCall.args[[\"aggr.y\"]][[\"threshold\"]] <- 1\n",
    "    ylim <- c(0.24,0.54)  \n",
    "  }\n",
    "  # The SDII do.call arguments  \n",
    "  if (zz == \"SDII\"){\n",
    "    doCall.args[[\"aggr.y\"]][[\"FUN\"]] <- \"index.meanGE\"\n",
    "    doCall.args[[\"aggr.y\"]][[\"threshold\"]] <- 1\n",
    "    ylim <- c(2,9)  \n",
    "  } \n",
    "  # The Mean do.call arguments    \n",
    "  if (zz == \"Mean\"){\n",
    "    doCall.args[[\"aggr.y\"]][[\"FUN\"]]   <- \"mean\"\n",
    "    doCall.args[[\"aggr.y\"]][[\"na.rm\"]] <- TRUE\n",
    "    ylim <- c(0,18)  \n",
    "  }    \n",
    "    \n",
    "  # We compute the index for the GCM ensemble. To do this, we loop over the temporal periods and then bind the serie along the time dimension with bindGrid function    \n",
    "  pred1 <- lapply(c(\"h\",\"ef\",\"mf\",\"ff\"), FUN = function(z) { \n",
    "    lapply(1:length(dName), FUN = function(zzz) {            \n",
    "      doCall.args[[\"grid\"]] <- loadGridData(dataset = paste0(\"./data/\",predictand,\"/y_\",z,\"_\",dName[zzz],\".nc4\"),var = var)\n",
    "      do.call(\"aggregateGrid\",doCall.args)\n",
    "    }) %>% bindGrid(dimension = \"member\")\n",
    "  }) %>% bindGrid(dimension = \"time\") \n",
    "  \n",
    "  # We compute the index for the RCM ensemble. To do this, we loop over the temporal periods and then bind the serie along the time dimension with bindGrid function\n",
    "  pred3 <- lapply(c(\"h\",\"ef\",\"mf\",\"ff\"), FUN = function(z) { \n",
    "    lapply(1:11, FUN = function(zzz) {            \n",
    "      doCall.args[[\"grid\"]] <- loadGridData(dataset = paste0(\"./data/\",predictand,\"/yRCM_\",z,\"_member\",zzz,\".nc4\"),var = var)\n",
    "      do.call(\"aggregateGrid\",doCall.args)\n",
    "    }) %>% bindGrid(dimension = \"member\")\n",
    "  }) %>% bindGrid(dimension = \"time\")\n",
    "    \n",
    "    # We compute the index for the DeepESD ensemble. To do this, we loop over the temporal periods and then bind the serie along the time dimension with bindGrid function    \n",
    "  pred2 <- lapply(c(\"h\",\"ef\",\"mf\",\"ff\"), FUN = function(z) { \n",
    "    lapply(1:length(dName), FUN = function(zzz) {            \n",
    "      doCall.args[[\"grid\"]] <- loadGridData(dataset = paste0(\"./data/\",predictand,\"/CNN_\",z,\"_\",dName[zzz],\".nc4\"),var = var)\n",
    "      do.call(\"aggregateGrid\",doCall.args)\n",
    "    }) %>% bindGrid(dimension = \"member\")\n",
    "  }) %>% bindGrid(dimension = \"time\")\n",
    "      \n",
    "  # We compute the index for the observed temporal serie \n",
    "  doCall.args[[\"grid\"]] <- y\n",
    "  y <- do.call(\"aggregateGrid\",doCall.args)\n",
    "  \n",
    "  # We call temporalPlot to plot the times-series \n",
    "  temporalPlot(\"OBS\" = y,\"GCM\" = pred1,\"RCM\" = pred3,\"CNN\" = pred2, cols = c(\"black\",\"red\",\"blue\",\"green\"),xyplot.custom = list(ylim = ylim))       \n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the resulting figures in .pdf format\n",
    "pdf(paste0(\"./figures/serie_\",var,\".pdf\"), width = 15, height = 4)\n",
    "grid.arrange(grobs = figs, ncol = 3)  \n",
    "dev.off()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "386px",
    "width": "400px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
